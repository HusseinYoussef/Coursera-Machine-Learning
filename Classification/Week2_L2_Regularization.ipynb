{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Specialization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRolDTzX98Rx",
        "outputId": "fd64e3e9-a074-4c68-df74-130bec8ff2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsf2asxy95cH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8kEUz5uRG9x"
      },
      "source": [
        "products = pd.read_csv('/content/drive/My Drive/ML Specialization/amazon_baby_subset.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IwuKZX3Glu_",
        "outputId": "55661cdd-971f-45d8-a572-30a18d386a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "products.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>We wanted to get something to keep track of ou...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
              "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lamaze Peekaboo, I Love You</td>\n",
              "      <td>One of baby's first and favorite books, and it...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
              "      <td>Very cute interactive book! My son loves this ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                name  ... sentiment\n",
              "0  Stop Pacifier Sucking without tears with Thumb...  ...         1\n",
              "1    Nature's Lullabies Second Year Sticker Calendar  ...         1\n",
              "2    Nature's Lullabies Second Year Sticker Calendar  ...         1\n",
              "3                        Lamaze Peekaboo, I Love You  ...         1\n",
              "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...  ...         1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4i1yK04IKSe"
      },
      "source": [
        "import json\n",
        "with open('/content/drive/My Drive/ML Specialization/important_words.json', 'r') as json_file:\n",
        "    important_words = json.load(json_file)\n",
        "with open('/content/drive/My Drive/ML Specialization/module-4-assignment-train-idx.json', 'r') as json_file:\n",
        "    train_indices = json.load(json_file)\n",
        "with open('/content/drive/My Drive/ML Specialization/module-4-assignment-validation-idx.json', 'r') as json_file:\n",
        "    valid_indices = json.load(json_file)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQ73kOxjgJP"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "\n",
        "    pattern = f'[{string.punctuation}]'\n",
        "    return re.sub(pattern, '', text)\n",
        "\n",
        "products = products.fillna({'review':''})\n",
        "products['review_clean'] = products['review'].apply(remove_punctuation)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeugV6j-JR4Z"
      },
      "source": [
        "for word in important_words:\n",
        "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi4QCr-fI1c-"
      },
      "source": [
        "train_data = products.iloc[train_indices]\n",
        "valid_data = products.iloc[valid_indices]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JyxHvaOcSFU"
      },
      "source": [
        "def get_numpy_data(dataframe, features, label):\n",
        "    \n",
        "    dataframe['constant'] = 1\n",
        "    features = ['constant'] + features\n",
        "    feature_matrix = np.array(dataframe[features])\n",
        "    label_array = np.array(dataframe[label])\n",
        "    return feature_matrix, label_array\n",
        "\n",
        "def predict_probability(feature_matrix, coefficients):\n",
        "    \n",
        "    score = np.dot(feature_matrix, coefficients)\n",
        "    predictions = 1 / (1 + np.exp(-score))\n",
        "    return predictions\n",
        "\n",
        "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
        "    \n",
        "    derivative = np.dot(errors, feature)\n",
        "\n",
        "    # add L2 penalty term for any feature that isn't the intercept.\n",
        "    if not feature_is_constant: \n",
        "        derivative -= l2_penalty * coefficient*2\n",
        "        \n",
        "    return derivative\n",
        "\n",
        "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
        "    indicator = (sentiment==+1)\n",
        "    scores = np.dot(feature_matrix, coefficients)\n",
        "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
        "    return lp"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8nR3A8JJufN",
        "outputId": "73350003-9c05-46d0-ca3e-a2b23a586031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "feature_matrix_train, sentiment_train = get_numpy_data(train_data, important_words, 'sentiment')\n",
        "feature_matrix_valid, sentiment_valid = get_numpy_data(valid_data, important_words, 'sentiment') "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4UDF0tvnlx1"
      },
      "source": [
        "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
        "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
        "    for itr in range(max_iter):\n",
        "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
        "        ## YOUR CODE HERE\n",
        "        predictions = predict_probability(feature_matrix, coefficients)\n",
        "        \n",
        "        # Compute indicator value for (y_i = +1)\n",
        "        indicator = (sentiment==+1)\n",
        "        \n",
        "        # Compute the errors as indicator - predictions\n",
        "        errors = indicator - predictions\n",
        "        for j in range(len(coefficients)): # loop over each coefficient\n",
        "            is_intercept = (j == 0)\n",
        "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
        "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
        "            ## YOUR CODE HERE\n",
        "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j], coefficients[j], l2_penalty, is_intercept)\n",
        "            \n",
        "            # add the step size times the derivative to the current coefficient\n",
        "            ## YOUR CODE HERE\n",
        "            coefficients[j] += step_size * derivative\n",
        "        \n",
        "        # Checking whether log likelihood is increasing\n",
        "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
        "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
        "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
        "            print('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
        "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
        "    return coefficients"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG0BMQhROQSA",
        "outputId": "c2b35299-4180-497d-ed59-86dfd3538925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "initial_coefficients = np.zeros(194)\n",
        "step_size = 5e-6\n",
        "max_iter = 501\n",
        "\n",
        "coefficients_0_penalty= logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients, step_size, 0, max_iter)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -29179.39138303\n",
            "iteration   1: log likelihood of observed labels = -29003.71259047\n",
            "iteration   2: log likelihood of observed labels = -28834.66187288\n",
            "iteration   3: log likelihood of observed labels = -28671.70781507\n",
            "iteration   4: log likelihood of observed labels = -28514.43078198\n",
            "iteration   5: log likelihood of observed labels = -28362.48344665\n",
            "iteration   6: log likelihood of observed labels = -28215.56713122\n",
            "iteration   7: log likelihood of observed labels = -28073.41743783\n",
            "iteration   8: log likelihood of observed labels = -27935.79536396\n",
            "iteration   9: log likelihood of observed labels = -27802.48168669\n",
            "iteration  10: log likelihood of observed labels = -27673.27331484\n",
            "iteration  11: log likelihood of observed labels = -27547.98083656\n",
            "iteration  12: log likelihood of observed labels = -27426.42679977\n",
            "iteration  13: log likelihood of observed labels = -27308.44444728\n",
            "iteration  14: log likelihood of observed labels = -27193.87673876\n",
            "iteration  15: log likelihood of observed labels = -27082.57555831\n",
            "iteration  20: log likelihood of observed labels = -26570.43059938\n",
            "iteration  30: log likelihood of observed labels = -25725.48742389\n",
            "iteration  40: log likelihood of observed labels = -25055.53326910\n",
            "iteration  50: log likelihood of observed labels = -24509.63590026\n",
            "iteration  60: log likelihood of observed labels = -24054.97906083\n",
            "iteration  70: log likelihood of observed labels = -23669.51640848\n",
            "iteration  80: log likelihood of observed labels = -23337.89167628\n",
            "iteration  90: log likelihood of observed labels = -23049.07066021\n",
            "iteration 100: log likelihood of observed labels = -22794.90974921\n",
            "iteration 200: log likelihood of observed labels = -21283.29527353\n",
            "iteration 300: log likelihood of observed labels = -20570.97485473\n",
            "iteration 400: log likelihood of observed labels = -20152.21466944\n",
            "iteration 500: log likelihood of observed labels = -19876.62333410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17a13T0iPgPX",
        "outputId": "307a7316-9502-41d8-881c-6ad5d77b5c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "coefficients_4_penalty= logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients, step_size, 4, max_iter)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -29179.39508175\n",
            "iteration   1: log likelihood of observed labels = -29003.73417180\n",
            "iteration   2: log likelihood of observed labels = -28834.71441858\n",
            "iteration   3: log likelihood of observed labels = -28671.80345068\n",
            "iteration   4: log likelihood of observed labels = -28514.58077957\n",
            "iteration   5: log likelihood of observed labels = -28362.69830317\n",
            "iteration   6: log likelihood of observed labels = -28215.85663259\n",
            "iteration   7: log likelihood of observed labels = -28073.79071393\n",
            "iteration   8: log likelihood of observed labels = -27936.26093762\n",
            "iteration   9: log likelihood of observed labels = -27803.04751805\n",
            "iteration  10: log likelihood of observed labels = -27673.94684207\n",
            "iteration  11: log likelihood of observed labels = -27548.76901327\n",
            "iteration  12: log likelihood of observed labels = -27427.33612958\n",
            "iteration  13: log likelihood of observed labels = -27309.48101569\n",
            "iteration  14: log likelihood of observed labels = -27195.04624253\n",
            "iteration  15: log likelihood of observed labels = -27083.88333261\n",
            "iteration  20: log likelihood of observed labels = -26572.49874392\n",
            "iteration  30: log likelihood of observed labels = -25729.32604153\n",
            "iteration  40: log likelihood of observed labels = -25061.34245801\n",
            "iteration  50: log likelihood of observed labels = -24517.52091982\n",
            "iteration  60: log likelihood of observed labels = -24064.99093939\n",
            "iteration  70: log likelihood of observed labels = -23681.67373669\n",
            "iteration  80: log likelihood of observed labels = -23352.19298741\n",
            "iteration  90: log likelihood of observed labels = -23065.50180166\n",
            "iteration 100: log likelihood of observed labels = -22813.44844580\n",
            "iteration 200: log likelihood of observed labels = -21321.14164794\n",
            "iteration 300: log likelihood of observed labels = -20624.98634439\n",
            "iteration 400: log likelihood of observed labels = -20219.92048845\n",
            "iteration 500: log likelihood of observed labels = -19956.11341777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujxcRR7NQzES",
        "outputId": "299a7e03-7014-4cc0-d9a5-870bb5713928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "coefficients_10_penalty= logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients, step_size, 10, max_iter)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -29179.40062984\n",
            "iteration   1: log likelihood of observed labels = -29003.76654163\n",
            "iteration   2: log likelihood of observed labels = -28834.79322654\n",
            "iteration   3: log likelihood of observed labels = -28671.94687528\n",
            "iteration   4: log likelihood of observed labels = -28514.80571589\n",
            "iteration   5: log likelihood of observed labels = -28363.02048079\n",
            "iteration   6: log likelihood of observed labels = -28216.29071186\n",
            "iteration   7: log likelihood of observed labels = -28074.35036891\n",
            "iteration   8: log likelihood of observed labels = -27936.95892966\n",
            "iteration   9: log likelihood of observed labels = -27803.89576265\n",
            "iteration  10: log likelihood of observed labels = -27674.95647005\n",
            "iteration  11: log likelihood of observed labels = -27549.95042714\n",
            "iteration  12: log likelihood of observed labels = -27428.69905549\n",
            "iteration  13: log likelihood of observed labels = -27311.03455140\n",
            "iteration  14: log likelihood of observed labels = -27196.79890162\n",
            "iteration  15: log likelihood of observed labels = -27085.84308528\n",
            "iteration  20: log likelihood of observed labels = -26575.59697506\n",
            "iteration  30: log likelihood of observed labels = -25735.07304608\n",
            "iteration  40: log likelihood of observed labels = -25070.03447306\n",
            "iteration  50: log likelihood of observed labels = -24529.31188025\n",
            "iteration  60: log likelihood of observed labels = -24079.95349572\n",
            "iteration  70: log likelihood of observed labels = -23699.83199186\n",
            "iteration  80: log likelihood of observed labels = -23373.54108747\n",
            "iteration  90: log likelihood of observed labels = -23090.01500055\n",
            "iteration 100: log likelihood of observed labels = -22841.08995135\n",
            "iteration 200: log likelihood of observed labels = -21377.25595328\n",
            "iteration 300: log likelihood of observed labels = -20704.63995428\n",
            "iteration 400: log likelihood of observed labels = -20319.25685307\n",
            "iteration 500: log likelihood of observed labels = -20072.16321721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMpsk6euQ1CJ",
        "outputId": "57db1b76-2fea-4b23-fb0b-4af59cfa0af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "coefficients_1e2_penalty= logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients, step_size, 1e2, max_iter)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -29179.48385120\n",
            "iteration   1: log likelihood of observed labels = -29004.25177457\n",
            "iteration   2: log likelihood of observed labels = -28835.97382190\n",
            "iteration   3: log likelihood of observed labels = -28674.09410083\n",
            "iteration   4: log likelihood of observed labels = -28518.17112932\n",
            "iteration   5: log likelihood of observed labels = -28367.83774654\n",
            "iteration   6: log likelihood of observed labels = -28222.77708939\n",
            "iteration   7: log likelihood of observed labels = -28082.70799392\n",
            "iteration   8: log likelihood of observed labels = -27947.37595368\n",
            "iteration   9: log likelihood of observed labels = -27816.54738615\n",
            "iteration  10: log likelihood of observed labels = -27690.00588850\n",
            "iteration  11: log likelihood of observed labels = -27567.54970126\n",
            "iteration  12: log likelihood of observed labels = -27448.98991327\n",
            "iteration  13: log likelihood of observed labels = -27334.14912742\n",
            "iteration  14: log likelihood of observed labels = -27222.86041863\n",
            "iteration  15: log likelihood of observed labels = -27114.96648229\n",
            "iteration  20: log likelihood of observed labels = -26621.50201299\n",
            "iteration  30: log likelihood of observed labels = -25819.72803950\n",
            "iteration  40: log likelihood of observed labels = -25197.34035501\n",
            "iteration  50: log likelihood of observed labels = -24701.03698195\n",
            "iteration  60: log likelihood of observed labels = -24296.66378580\n",
            "iteration  70: log likelihood of observed labels = -23961.38842316\n",
            "iteration  80: log likelihood of observed labels = -23679.38088853\n",
            "iteration  90: log likelihood of observed labels = -23439.31824267\n",
            "iteration 100: log likelihood of observed labels = -23232.88192018\n",
            "iteration 200: log likelihood of observed labels = -22133.50726528\n",
            "iteration 300: log likelihood of observed labels = -21730.03957488\n",
            "iteration 400: log likelihood of observed labels = -21545.87572145\n",
            "iteration 500: log likelihood of observed labels = -21451.95551390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZwxhTjPQ2Nz",
        "outputId": "b89daa9e-2e21-45af-a9e2-cedc773c5ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "coefficients_1e3_penalty= logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients, step_size, 1e3, max_iter)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -29180.31606471\n",
            "iteration   1: log likelihood of observed labels = -29009.07176112\n",
            "iteration   2: log likelihood of observed labels = -28847.62378912\n",
            "iteration   3: log likelihood of observed labels = -28695.14439397\n",
            "iteration   4: log likelihood of observed labels = -28550.95060743\n",
            "iteration   5: log likelihood of observed labels = -28414.45771129\n",
            "iteration   6: log likelihood of observed labels = -28285.15124375\n",
            "iteration   7: log likelihood of observed labels = -28162.56976044\n",
            "iteration   8: log likelihood of observed labels = -28046.29387744\n",
            "iteration   9: log likelihood of observed labels = -27935.93902900\n",
            "iteration  10: log likelihood of observed labels = -27831.15045502\n",
            "iteration  11: log likelihood of observed labels = -27731.59955260\n",
            "iteration  12: log likelihood of observed labels = -27636.98108219\n",
            "iteration  13: log likelihood of observed labels = -27547.01092670\n",
            "iteration  14: log likelihood of observed labels = -27461.42422295\n",
            "iteration  15: log likelihood of observed labels = -27379.97375625\n",
            "iteration  20: log likelihood of observed labels = -27027.18208317\n",
            "iteration  30: log likelihood of observed labels = -26527.22737267\n",
            "iteration  40: log likelihood of observed labels = -26206.59048765\n",
            "iteration  50: log likelihood of observed labels = -25995.96903148\n",
            "iteration  60: log likelihood of observed labels = -25854.95710284\n",
            "iteration  70: log likelihood of observed labels = -25759.08109950\n",
            "iteration  80: log likelihood of observed labels = -25693.05688014\n",
            "iteration  90: log likelihood of observed labels = -25647.09929349\n",
            "iteration 100: log likelihood of observed labels = -25614.81468705\n",
            "iteration 200: log likelihood of observed labels = -25536.20998919\n",
            "iteration 300: log likelihood of observed labels = -25532.57691220\n",
            "iteration 400: log likelihood of observed labels = -25532.35543765\n",
            "iteration 500: log likelihood of observed labels = -25532.33970049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bghkwiWXQ3dp",
        "outputId": "09c0a4b9-79b9-43fb-be03-85d26d2c7c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "coefficients_1e5_penalty= logistic_regression_with_L2(feature_matrix_train, sentiment_train, initial_coefficients, step_size, 1e5, max_iter)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration   0: log likelihood of observed labels = -29271.85955115\n",
            "iteration   1: log likelihood of observed labels = -29271.71006589\n",
            "iteration   2: log likelihood of observed labels = -29271.65738833\n",
            "iteration   3: log likelihood of observed labels = -29271.61189923\n",
            "iteration   4: log likelihood of observed labels = -29271.57079975\n",
            "iteration   5: log likelihood of observed labels = -29271.53358505\n",
            "iteration   6: log likelihood of observed labels = -29271.49988440\n",
            "iteration   7: log likelihood of observed labels = -29271.46936584\n",
            "iteration   8: log likelihood of observed labels = -29271.44172890\n",
            "iteration   9: log likelihood of observed labels = -29271.41670149\n",
            "iteration  10: log likelihood of observed labels = -29271.39403722\n",
            "iteration  11: log likelihood of observed labels = -29271.37351294\n",
            "iteration  12: log likelihood of observed labels = -29271.35492661\n",
            "iteration  13: log likelihood of observed labels = -29271.33809523\n",
            "iteration  14: log likelihood of observed labels = -29271.32285309\n",
            "iteration  15: log likelihood of observed labels = -29271.30905015\n",
            "iteration  20: log likelihood of observed labels = -29271.25729150\n",
            "iteration  30: log likelihood of observed labels = -29271.20657205\n",
            "iteration  40: log likelihood of observed labels = -29271.18775997\n",
            "iteration  50: log likelihood of observed labels = -29271.18078247\n",
            "iteration  60: log likelihood of observed labels = -29271.17819447\n",
            "iteration  70: log likelihood of observed labels = -29271.17723457\n",
            "iteration  80: log likelihood of observed labels = -29271.17687853\n",
            "iteration  90: log likelihood of observed labels = -29271.17674648\n",
            "iteration 100: log likelihood of observed labels = -29271.17669750\n",
            "iteration 200: log likelihood of observed labels = -29271.17666862\n",
            "iteration 300: log likelihood of observed labels = -29271.17666862\n",
            "iteration 400: log likelihood of observed labels = -29271.17666862\n",
            "iteration 500: log likelihood of observed labels = -29271.17666862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QCKjRFsQ-WK",
        "outputId": "d92bf3b7-50f2-4947-b7f1-1236d8454055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "lst = []\n",
        "for i in range(1, len(coefficients_0_penalty)):\n",
        "    lst.append((coefficients_0_penalty[i], important_words[i-1]))\n",
        "lst.sort(reverse=True)\n",
        "pos = lst[:5]\n",
        "neg = lst[-5:]\n",
        "print(pos)\n",
        "print(neg)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1.0585539820695435, 'love'), (1.0524840477983537, 'loves'), (0.9845588198731923, 'easy'), (0.8356932076383463, 'perfect'), (0.8016249897781762, 'great')]\n",
            "[(-0.5727070451581127, 'returned'), (-0.6178091779812257, 'waste'), (-0.7420849546350395, 'return'), (-0.7687931346121052, 'money'), (-0.9554366281707273, 'disappointed')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGuPjKrWVLu2",
        "outputId": "6c7d8bdf-587f-4bf8-eeaa-64a64915292f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for coeff in [coefficients_0_penalty, coefficients_4_penalty, coefficients_10_penalty,\n",
        "              coefficients_1e2_penalty, coefficients_1e3_penalty, coefficients_1e5_penalty]:\n",
        "    prob = predict_probability(feature_matrix_train, coeff)\n",
        "    print(np.sum((prob > 0.5) == (sentiment_train == 1)) / len(sentiment_train))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7851561577866434\n",
            "0.7851089445480512\n",
            "0.7849909114515711\n",
            "0.7839758268218409\n",
            "0.7758551497839994\n",
            "0.6803663747314747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olo3n6y2XRau",
        "outputId": "148d8980-1794-4271-dcb3-a1c95d3c3b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "for coeff in [coefficients_0_penalty, coefficients_4_penalty, coefficients_10_penalty,\n",
        "              coefficients_1e2_penalty, coefficients_1e3_penalty, coefficients_1e5_penalty]:\n",
        "    prob = predict_probability(feature_matrix_valid, coeff)\n",
        "    print(np.sum((prob > 0.5) == (sentiment_valid == 1)) / len(sentiment_valid))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.781439641490057\n",
            "0.7815330034543927\n",
            "0.7817197273830642\n",
            "0.781066193632714\n",
            "0.7713565493417982\n",
            "0.667818130893474\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}